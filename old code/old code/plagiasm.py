import streamlit as st
import os
from dotenv import load_dotenv

# OpenAI & LangChain imports
import openai
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# File parsers
from PyPDF2 import PdfReader
from docx import Document as DocxDocument

# --- Load environment variables ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not found in .env")
openai.api_key = OPENAI_API_KEY

# --- Extract text from supported files ---
def extract_text(file) -> str:
    if file.type == "application/pdf":
        reader = PdfReader(file)
        return "".join(page.extract_text() or "" for page in reader.pages)

    elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = DocxDocument(file)
        return "\n".join(p.text for p in doc.paragraphs)

    elif file.type == "text/plain":
        return file.read().decode("utf-8")

    else:
        return "‚ùå –§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è."

# --- Build and persist Chroma vector store ---
@st.cache_resource(show_spinner=False)
def build_vector_store(texts: list[str], persist_dir: str = "./chroma_store") -> Chroma:
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = []
    for i, txt in enumerate(texts):
        chunks = splitter.split_text(txt)
        docs.extend([Document(page_content=chunk, metadata={"source": f"doc_{i}"}) for chunk in chunks])

    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma.from_documents(docs, embeddings, persist_directory=persist_dir)
    vectordb.persist()
    return vectordb

# --- Load vector store and set up retrieval QA ---
@st.cache_resource(show_spinner=False)
def get_retriever(k: int = 5) -> RetrievalQA:
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma(persist_directory="./chroma_store", embedding_function=embeddings)
    retriever = vectordb.as_retriever(search_kwargs={"k": k})
    llm = OpenAI(temperature=0, max_tokens=500, openai_api_key=OPENAI_API_KEY)
    return RetrievalQA.from_chain_type(llm, chain_type="stuff", retriever=retriever)

# --- Streamlit UI ---
st.set_page_config(page_title="RAG Plagiarism Checker", layout="centered")
st.title("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç —Å –ø–æ–º–æ—â—å—é GPT + LangChain")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —á—Ç–æ–±—ã –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å, –∑–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç.")

# Step 1: Upload reference documents
ref_files = st.file_uploader(
    "üìö –ó–∞–≥—Ä—É–∑–∏—Ç–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (.txt, .pdf, .docx)",
    accept_multiple_files=True,
    type=["txt", "pdf", "docx"]
)
if ref_files:
    if st.button("üîß –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å"):
        with st.spinner("–ò–¥—ë—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞..."):
            texts = [extract_text(f) for f in ref_files]
            build_vector_store(texts)
        st.success("–ò–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω!")

# Step 2: Upload file to check
uploaded_file = st.file_uploader(
    "üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç",
    type=["txt", "pdf", "docx"],
    key="check"
)
if uploaded_file:
    full_text = extract_text(uploaded_file)
    text_to_check = full_text[:3000]  # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
    st.subheader("üìå –§—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    st.text_area("", text_to_check[:1000], height=200)

    if st.button("üö® –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç"):
        with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑..."):
            qa = get_retriever()
            query = (
                "–û—Ü–µ–Ω–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –ø–ª–∞–≥–∏–∞—Ç–æ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. "
                "–ï—Å–ª–∏ –¥–∞, —É–∫–∞–∂–∏ –ø–æ—Ö–æ–∂–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–ª–∞–≥–∏–∞—Ç–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (0-100%).\n\n"
                f"–¢–µ–∫—Å—Ç:\n{text_to_check}"
            )
            result = qa.run(query)
        st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞")
        st.write(result)

# Footer
st.markdown("---")
st.markdown("üîß –°–¥–µ–ª–∞–Ω–æ —Å ‚ù§Ô∏è –Ω–∞ –æ—Å–Ω–æ–≤–µ Streamlit, LangChain –∏ OpenAI GPT")

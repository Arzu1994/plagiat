import streamlit as st
import os
from dotenv import load_dotenv

# OpenAI & LangChain imports
import openai
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# PDF/text parsing
from PyPDF2 import PdfReader

# --- Load environment variables ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not found in .env")
openai.api_key = OPENAI_API_KEY

# --- Document Ingestion and Indexing ---
def extract_text(file) -> str:
    """Extract text from uploaded PDF or text file"""
    if file.type == "application/pdf":
        reader = PdfReader(file)
        text = "".join(page.extract_text() or "" for page in reader.pages)
    else:
        text = file.read().decode("utf-8")
    return text

@st.cache_data(show_spinner=False)
def build_vector_store(texts: list[str], persist_dir: str = "./chroma_store") -> Chroma:
    """Build or load a Chroma vector store from raw texts"""
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = []
    for i, txt in enumerate(texts):
        chunks = splitter.split_text(txt)
        docs.extend([Document(page_content=chunk, metadata={"source": f"doc_{i}"}) for chunk in chunks])

    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma.from_documents(docs, embeddings, persist_directory=persist_dir)
    vectordb.persist()
    return vectordb

@st.cache_resource(show_spinner=False)
def get_retriever(k: int = 5) -> RetrievalQA:
    """Load chroma store and return a RetrievalQA chain"""
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma(persist_directory="./chroma_store", embedding_function=embeddings)
    retriever = vectordb.as_retriever(search_kwargs={"k": k})
    llm = OpenAI(temperature=0, max_tokens=500, openai_api_key=OPENAI_API_KEY)
    return RetrievalQA.from_chain_type(llm, chain_type="stuff", retriever=retriever)

# --- Streamlit UI ---
st.set_page_config(page_title="RAG Plagiarism Checker", layout="centered")
st.title("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç —Å –ø–æ–º–æ—â—å—é GPT + LangChain")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —á—Ç–æ–±—ã –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å, –∑–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç.")

# Step 1: Upload reference documents
ref_files = st.file_uploader("üìö –ó–∞–≥—Ä—É–∑–∏—Ç–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (.txt –∏–ª–∏ .pdf)", accept_multiple_files=True, type=["txt", "pdf"])
if ref_files:
    if st.button("üîß –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å"):
        with st.spinner("–ò–¥—ë—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞..."):
            texts = [extract_text(f) for f in ref_files]
            build_vector_store(texts)
        st.success("–ò–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω!")

# Step 2: Upload file to check
uploaded_file = st.file_uploader("üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç", type=["txt", "pdf"], key="check")
if uploaded_file:
    full_text = extract_text(uploaded_file)
    text_to_check = full_text[:3000]  # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
    st.subheader("üìå –§—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    st.text_area("", text_to_check[:1000], height=200)

    if st.button("üö® –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –ø–ª–∞–≥–∏–∞—Ç"):
        with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑..."):
            qa = get_retriever()
            query = (
                "–û—Ü–µ–Ω–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –ø–ª–∞–≥–∏–∞—Ç–æ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. "
                "–ï—Å–ª–∏ –¥–∞, —É–∫–∞–∂–∏ –ø–æ—Ö–æ–∂–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–ª–∞–≥–∏–∞—Ç–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (0-100%).\n\n"
                f"–¢–µ–∫—Å—Ç:\n{text_to_check}"
            )
            result = qa.run(query)
        st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞")
        st.write(result)

# Footer
st.markdown("---")
st.markdown("üîß –°–¥–µ–ª–∞–Ω–æ —Å ‚ù§Ô∏è –Ω–∞ –æ—Å–Ω–æ–≤–µ Streamlit, LangChain –∏ OpenAI GPT")
